{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Obtaining baseline results using Yolo models "
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Data"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Converting Geojson to YOLO"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "from glob import glob\n",
                "from PIL import Image\n",
                "\n",
                "def fix_path(path: str) -> str:\n",
                "    return path.replace(\"\\\\\", \"/\")\n",
                "\n",
                "# Directories\n",
                "labels_dir = fix_path(r\"datasets\\Planet\\labels\")\n",
                "source_dir = fix_path(r\"datasets\\Planet\\jpg_source\")\n",
                "output_dir = fix_path(\"datasets/Planet/yolo_labels\")\n",
                "\n",
                "# Ensure output directory exists\n",
                "os.makedirs(output_dir, exist_ok=True)\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "  0%|          | 0/739 [00:00<?, ?it/s]"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "100%|██████████| 739/739 [00:08<00:00, 86.18it/s]"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Conversion complete!\n"
                    ]
                },
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import numpy as np\n",
                "from glob import glob\n",
                "from PIL import Image\n",
                "from tqdm import tqdm\n",
                "\n",
                "# Class mapping\n",
                "class_map = {\n",
                "    \"marine_debris\": 0  # Update with additional classes if needed\n",
                "}\n",
                "\n",
                "# Normalize bounding box coordinates\n",
                "def normalize_bbox(bbox, img_width, img_height):\n",
                "    x_min, y_min, x_max, y_max = bbox\n",
                "    x_center = (x_min + x_max) / 2 / img_width\n",
                "    y_center = (y_min + y_max) / 2 / img_height\n",
                "    width = (x_max - x_min) / img_width\n",
                "    height = (y_max - y_min) / img_height\n",
                "    return x_center, y_center, width, height\n",
                "\n",
                "# Process .npy files\n",
                "npy_files = glob(os.path.join(labels_dir, \"*.npy\"))\n",
                "\n",
                "for npy_file in tqdm(npy_files):\n",
                "    # Load .npy data\n",
                "    data = np.load(npy_file, allow_pickle=True).tolist()\n",
                "\n",
                "    # Get corresponding image dimensions\n",
                "    base_name = os.path.splitext(os.path.basename(npy_file))[0]\n",
                "    image_path = os.path.join(source_dir, base_name + \".jpg\")\n",
                "    \n",
                "    if not os.path.exists(image_path):\n",
                "        print(f\"Image not found for {base_name}, skipping...\")\n",
                "        continue\n",
                "\n",
                "    with Image.open(image_path) as img:\n",
                "        img_width, img_height = img.size\n",
                "\n",
                "    # Create YOLO label file\n",
                "    yolo_file_path = os.path.join(output_dir, base_name + \".txt\")\n",
                "    with open(yolo_file_path, \"w\") as yolo_file:\n",
                "        for entry in data:\n",
                "            x_min, y_min, x_max, y_max, class_id = entry\n",
                "            if class_id > 0:\n",
                "                class_id -= 1\n",
                "\n",
                "            # Normalize the bounding box coordinates\n",
                "            x_center, y_center, width, height = normalize_bbox(\n",
                "                (x_min, y_min, x_max, y_max), img_width, img_height\n",
                "            )\n",
                "\n",
                "            # Write to YOLO file\n",
                "            yolo_file.write(f\"{class_id} {x_center:.6f} {y_center:.6f} {width:.6f} {height:.6f}\\n\")\n",
                "\n",
                "print(\"Conversion complete!\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Splitting Dataset"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset split completed.\n",
                        "Train files: 517\n",
                        "Validation files: 148\n",
                        "Test files: 74\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import shutil\n",
                "from sklearn.model_selection import train_test_split\n",
                "\n",
                "# Define paths\n",
                "labels_dir = \"datasets/Planet/yolo_labels\"\n",
                "images_dir = \"datasets/Planet/jpg_source\"\n",
                "output_dir = \"datasets/Planet/dataset_splits\"\n",
                "\n",
                "# Ratios\n",
                "train_ratio = 0.7\n",
                "val_ratio = 0.2\n",
                "test_ratio = 0.1\n",
                "\n",
                "# Ensure the ratios sum to 1\n",
                "assert round(train_ratio + val_ratio + test_ratio, 5) == 1.0, \"Ratios must sum to 1.\"\n",
                "\n",
                "# Get list of label files\n",
                "label_files = [f for f in os.listdir(labels_dir) if f.endswith(\".txt\")]\n",
                "\n",
                "# Split into train, validation, and test\n",
                "train_files, temp_files = train_test_split(label_files, test_size=(1 - train_ratio), random_state=42, shuffle=True)\n",
                "val_files, test_files = train_test_split(temp_files, test_size=(test_ratio / (test_ratio + val_ratio)), random_state=42, shuffle=True)\n",
                "\n",
                "# Function to move files\n",
                "def move_files(files, dest_images, dest_labels):\n",
                "    os.makedirs(dest_images, exist_ok=True)\n",
                "    os.makedirs(dest_labels, exist_ok=True)\n",
                "    for label_file in files:\n",
                "        # Move label file\n",
                "        src_label = os.path.join(labels_dir, label_file)\n",
                "        dest_label = os.path.join(dest_labels, label_file)\n",
                "        shutil.copy(src_label, dest_label)\n",
                "\n",
                "        # Move corresponding image file\n",
                "        image_file = label_file.replace(\".txt\", \".jpg\")  # Assuming images are .jpg\n",
                "        src_image = os.path.join(images_dir, image_file)\n",
                "        dest_image = os.path.join(dest_images, image_file)\n",
                "        if os.path.exists(src_image):\n",
                "            shutil.copy(src_image, dest_image)\n",
                "        else:\n",
                "            print(f\"Image file {image_file} not found for label {label_file}\")\n",
                "\n",
                "# Move files to respective directories\n",
                "move_files(train_files, os.path.join(output_dir, \"train/images\"), os.path.join(output_dir, \"train/labels\"))\n",
                "move_files(val_files, os.path.join(output_dir, \"val/images\"), os.path.join(output_dir, \"val/labels\"))\n",
                "move_files(test_files, os.path.join(output_dir, \"test/images\"), os.path.join(output_dir, \"test/labels\"))\n",
                "\n",
                "print(\"Dataset split completed.\")\n",
                "print(f\"Train files: {len(train_files)}\")\n",
                "print(f\"Validation files: {len(val_files)}\")\n",
                "print(f\"Test files: {len(test_files)}\")\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "#### Augmentation"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Dataset augmentation completed.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "import shutil\n",
                "import random\n",
                "from glob import glob\n",
                "from PIL import Image, ImageOps\n",
                "\n",
                "def fix_path(path: str) -> str:\n",
                "    return path.replace(\"\\\\\", \"/\")\n",
                "\n",
                "# Directories\n",
                "labels_dir = fix_path(r\"yolo_labels\")\n",
                "source_dir = fix_path(r\"NASA_Planet_Data\\source\")\n",
                "output_dir = fix_path(r\"aug\")\n",
                "\n",
                "# Ensure output directories exist\n",
                "os.makedirs(output_dir, exist_ok=True)\n",
                "augmented_images_dir = os.path.join(output_dir, \"images\")\n",
                "augmented_labels_dir = os.path.join(output_dir, \"labels\")\n",
                "os.makedirs(augmented_images_dir, exist_ok=True)\n",
                "os.makedirs(augmented_labels_dir, exist_ok=True)\n",
                "\n",
                "# Augmentation functions\n",
                "def augment_image(image, label_path, base_name, augmentation_type):\n",
                "    augmented_image = image.copy()\n",
                "    if augmentation_type == \"flip\":\n",
                "        augmented_image = ImageOps.mirror(image)\n",
                "    elif augmentation_type == \"rotate\":\n",
                "        augmented_image = image.rotate(90, expand=True)\n",
                "    \n",
                "    # Save augmented image\n",
                "    augmented_image_path = os.path.join(augmented_images_dir, f\"{base_name}_{augmentation_type}.jpg\")\n",
                "    augmented_image.save(augmented_image_path)\n",
                "\n",
                "    # Copy corresponding label file\n",
                "    if os.path.exists(label_path):\n",
                "        augmented_label_path = os.path.join(augmented_labels_dir, f\"{base_name}_{augmentation_type}.txt\")\n",
                "        shutil.copy(label_path, augmented_label_path)\n",
                "    else:\n",
                "        print(f\"Label file {label_path} missing for image {base_name}, skipping...\")\n",
                "\n",
                "# Process images and labels\n",
                "image_files = glob(os.path.join(source_dir, \"*.jpg\"))\n",
                "for image_path in image_files:\n",
                "    base_name = os.path.splitext(os.path.basename(image_path))[0]\n",
                "    label_path = os.path.join(labels_dir, f\"{base_name}.txt\")\n",
                "\n",
                "    if not os.path.exists(label_path):\n",
                "        print(f\"Label file missing for {base_name}, skipping...\")\n",
                "        continue\n",
                "\n",
                "    with Image.open(image_path) as img:\n",
                "        # Save original image and label\n",
                "        img.save(os.path.join(augmented_images_dir, f\"{base_name}.jpg\"))\n",
                "        shutil.copy(label_path, os.path.join(augmented_labels_dir, f\"{base_name}.txt\"))\n",
                "\n",
                "        # Apply augmentations\n",
                "        augment_image(img, label_path, base_name, \"flip\")\n",
                "        augment_image(img, label_path, base_name, \"rotate\")\n",
                "\n",
                "print(\"Dataset augmentation completed.\")\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Number of augmented images: 2217\n",
                        "Number of augmented labels: 2217\n",
                        "Dataset is consistent: Images and labels match.\n"
                    ]
                }
            ],
            "source": [
                "import os\n",
                "\n",
                "# Directories for augmented dataset\n",
                "augmented_images_dir = r\"aug\\images\"\n",
                "augmented_labels_dir = r\"aug\\labels\"\n",
                "\n",
                "# Count the number of image and label files\n",
                "num_images = len([f for f in os.listdir(augmented_images_dir) if f.endswith(\".jpg\")])\n",
                "num_labels = len([f for f in os.listdir(augmented_labels_dir) if f.endswith(\".txt\")])\n",
                "\n",
                "# Print the counts\n",
                "print(f\"Number of augmented images: {num_images}\")\n",
                "print(f\"Number of augmented labels: {num_labels}\")\n",
                "\n",
                "# Ensure the counts match\n",
                "if num_images != num_labels:\n",
                "    print(\"Warning: The number of images and labels do not match!\")\n",
                "else:\n",
                "    print(\"Dataset is consistent: Images and labels match.\")\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "marine_debris",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.16"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
